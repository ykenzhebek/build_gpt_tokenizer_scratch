{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare get_stats and merge function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids, counts=None):\n",
    "    counts = {} if counts is None else counts\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n",
      "[72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello World!\"\n",
    "tokens = text.encode(\"utf-8\")\n",
    "print(tokens)\n",
    "tokens = list(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(72, 101): 1, (101, 108): 1, (108, 108): 1, (108, 111): 1, (111, 32): 1, (32, 87): 1, (87, 111): 1, (111, 114): 1, (114, 108): 1, (108, 100): 1, (100, 33): 1}\n"
     ]
    }
   ],
   "source": [
    "stats = get_stats(tokens)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    new_ids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            new_ids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i += 1\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 101, 9, 1]\n"
     ]
    }
   ],
   "source": [
    "print(merge([5, 6, 6, 7, 9, 1], (6, 7), 101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: BasicTokenizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the BasicTokenizer class, with the following three core functions:\n",
    "\n",
    "- def train(self, text, vocab_size, verbose=False)\n",
    "- def encode(self, text)\n",
    "- def decode(self, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'b'\n",
      "b'\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklm'\n"
     ]
    }
   ],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "\n",
    "print(vocab[98])\n",
    "\n",
    "tokens = b\"\".join(vocab[idx] for idx in range(110))\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        \n",
    "        raw_bytes = text.encode(\"utf-8\")  # converting text to raw bytes using utf-8 encoding\n",
    "        ids = list(raw_bytes)  # converting to list of integers in range 0..255\n",
    "\n",
    "        assert vocab_size >= 256\n",
    "        num_merges = vocab_size - 256\n",
    "\n",
    "        merges = {} # (int, int) : int\n",
    "        vocab = {idx: bytes([idx]) for idx in range(256)}  # int : bytes\n",
    "        \n",
    "        for i in range(num_merges):\n",
    "            # count the number of frequency of consecutive pairs\n",
    "            stats = get_stats(ids)\n",
    "            # chose the pair with the highest count \n",
    "            pair = max(stats, key=stats.get)\n",
    "            # create new token : assignt it next available id\n",
    "            idx = i + 256\n",
    "            \n",
    "            # replace all occurances of pair in ids with idx\n",
    "            ids = merge(ids, pair, idx)\n",
    "\n",
    "            # save the merge\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
    "\n",
    "            # prints \n",
    "            if verbose:\n",
    "                print(f'merge {i+1}/{num_merges} : {pair} -> {idx} ({vocab[idx]}) had {stats[pair]} occurences')\n",
    "        \n",
    "        # save merges and vocab\n",
    "        self.merges = merges  # used in encode()\n",
    "        self.vocab = vocab  # used in decode()\n",
    "\n",
    "    def encode(self, text):\n",
    "        ''' given a string, return list of integers (the tokens)'''\n",
    "        \n",
    "        ids = list(text.encode(\"utf-8\")) \n",
    "        while len(ids) >= 2:\n",
    "            stats = get_stats(ids)\n",
    "            # find pair with lowest idx in merges\n",
    "            pair = min(stats, key=lambda p : self.merges.get(p, float(\"inf\")))\n",
    "            \n",
    "            if pair not in self.merges:\n",
    "                break # nothing else can be merged\n",
    "\n",
    "            # identify the index from merges\n",
    "            idx = self.merges[pair]\n",
    "            # merge the pair(lowest merge index)\n",
    "            ids = merge(ids, pair, idx)\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        ''' given list of integers(token ids), return python string '''\n",
    "        # iterating through ids and finding appropriate bytes for that idx from vocab\n",
    "        text_bytes = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        # just decode using utf-8\n",
    "        text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your tokenizer \n",
    "\n",
    "One default test you may wish to use is the text file tests/taylorswift.txt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BasicTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of text:  185768\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(\"taylorswift.txt\", 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"the length of text: \", len(raw_text))\n",
    "#print(raw_text[850 : 2050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1/244 : (101, 32) -> 256 (b'e ') had 2981 occurences\n",
      "merge 2/244 : (44, 32) -> 257 (b', ') had 2961 occurences\n",
      "merge 3/244 : (100, 32) -> 258 (b'd ') had 2617 occurences\n",
      "merge 4/244 : (46, 32) -> 259 (b'. ') had 2560 occurences\n",
      "merge 5/244 : (114, 32) -> 260 (b'r ') had 2428 occurences\n",
      "merge 6/244 : (50, 48) -> 261 (b'20') had 2365 occurences\n",
      "merge 7/244 : (115, 32) -> 262 (b's ') had 2053 occurences\n",
      "merge 8/244 : (105, 110) -> 263 (b'in') had 2006 occurences\n",
      "merge 9/244 : (111, 110) -> 264 (b'on') had 1815 occurences\n",
      "merge 10/244 : (114, 105) -> 265 (b'ri') had 1805 occurences\n",
      "merge 11/244 : (116, 32) -> 266 (b't ') had 1802 occurences\n",
      "merge 12/244 : (116, 104) -> 267 (b'th') had 1737 occurences\n",
      "merge 13/244 : (101, 258) -> 268 (b'ed ') had 1736 occurences\n",
      "merge 14/244 : (257, 261) -> 269 (b', 20') had 1705 occurences\n",
      "merge 15/244 : (97, 110) -> 270 (b'an') had 1487 occurences\n",
      "merge 16/244 : (97, 114) -> 271 (b'ar') had 1360 occurences\n",
      "merge 17/244 : (101, 260) -> 272 (b'er ') had 1356 occurences\n",
      "merge 18/244 : (121, 32) -> 273 (b'y ') had 1248 occurences\n",
      "merge 19/244 : (97, 108) -> 274 (b'al') had 1164 occurences\n",
      "merge 20/244 : (267, 256) -> 275 (b'the ') had 1142 occurences\n",
      "merge 21/244 : (118, 268) -> 276 (b'ved ') had 1104 occurences\n",
      "merge 22/244 : (119, 105) -> 277 (b'wi') had 1049 occurences\n",
      "merge 23/244 : (101, 114) -> 278 (b'er') had 897 occurences\n",
      "merge 24/244 : (264, 32) -> 279 (b'on ') had 880 occurences\n",
      "merge 25/244 : (277, 102) -> 280 (b'wif') had 871 occurences\n",
      "merge 26/244 : (82, 101) -> 281 (b'Re') had 870 occurences\n",
      "merge 27/244 : (83, 280) -> 282 (b'Swif') had 867 occurences\n",
      "merge 28/244 : (111, 260) -> 283 (b'or ') had 859 occurences\n",
      "merge 29/244 : (99, 104) -> 284 (b'ch') had 816 occurences\n",
      "merge 30/244 : (269, 49) -> 285 (b', 201') had 811 occurences\n",
      "merge 31/244 : (111, 109) -> 286 (b'om') had 789 occurences\n",
      "merge 32/244 : (98, 272) -> 287 (b'ber ') had 752 occurences\n",
      "merge 33/244 : (32, 275) -> 288 (b' the ') had 748 occurences\n",
      "merge 34/244 : (97, 121) -> 289 (b'ay') had 744 occurences\n",
      "merge 35/244 : (101, 110) -> 290 (b'en') had 740 occurences\n",
      "merge 36/244 : (111, 114) -> 291 (b'or') had 737 occurences\n",
      "merge 37/244 : (274, 32) -> 292 (b'al ') had 705 occurences\n",
      "merge 38/244 : (101, 109) -> 293 (b'em') had 703 occurences\n",
      "merge 39/244 : (46, 10) -> 294 (b'.\\n') had 685 occurences\n",
      "merge 40/244 : (265, 101) -> 295 (b'rie') had 685 occurences\n",
      "merge 41/244 : (263, 103) -> 296 (b'ing') had 684 occurences\n",
      "merge 42/244 : (269, 50) -> 297 (b', 202') had 673 occurences\n",
      "merge 43/244 : (116, 105) -> 298 (b'ti') had 666 occurences\n",
      "merge 44/244 : (289, 108) -> 299 (b'ayl') had 654 occurences\n",
      "merge 45/244 : (34, 259) -> 300 (b'\". ') had 651 occurences\n",
      "merge 46/244 : (108, 108) -> 301 (b'll') had 649 occurences\n",
      "merge 47/244 : (84, 299) -> 302 (b'Tayl') had 647 occurences\n",
      "merge 48/244 : (116, 295) -> 303 (b'trie') had 644 occurences\n",
      "merge 49/244 : (294, 32) -> 304 (b'.\\n ') had 643 occurences\n",
      "merge 50/244 : (116, 111) -> 305 (b'to') had 642 occurences\n",
      "merge 51/244 : (259, 281) -> 306 (b'. Re') had 640 occurences\n",
      "merge 52/244 : (306, 303) -> 307 (b'. Retrie') had 639 occurences\n",
      "merge 53/244 : (307, 276) -> 308 (b'. Retrieved ') had 639 occurences\n",
      "merge 54/244 : (302, 283) -> 309 (b'Taylor ') had 611 occurences\n",
      "merge 55/244 : (101, 115) -> 310 (b'es') had 606 occurences\n",
      "merge 56/244 : (309, 282) -> 311 (b'Taylor Swif') had 598 occurences\n",
      "merge 57/244 : (117, 115) -> 312 (b'us') had 561 occurences\n",
      "merge 58/244 : (114, 286) -> 313 (b'rom') had 532 occurences\n",
      "merge 59/244 : (293, 287) -> 314 (b'ember ') had 528 occurences\n",
      "merge 60/244 : (41, 259) -> 315 (b'). ') had 524 occurences\n",
      "merge 61/244 : (65, 114) -> 316 (b'Ar') had 509 occurences\n",
      "merge 62/244 : (102, 313) -> 317 (b'from') had 503 occurences\n",
      "merge 63/244 : (315, 34) -> 318 (b'). \"') had 499 occurences\n",
      "merge 64/244 : (270, 258) -> 319 (b'and ') had 498 occurences\n",
      "merge 65/244 : (114, 101) -> 320 (b're') had 495 occurences\n",
      "merge 66/244 : (111, 117) -> 321 (b'ou') had 487 occurences\n",
      "merge 67/244 : (111, 265) -> 322 (b'ori') had 469 occurences\n",
      "merge 68/244 : (111, 102) -> 323 (b'of') had 466 occurences\n",
      "merge 69/244 : (103, 263) -> 324 (b'gin') had 465 occurences\n",
      "merge 70/244 : (296, 32) -> 325 (b'ing ') had 464 occurences\n",
      "merge 71/244 : (284, 105) -> 326 (b'chi') had 458 occurences\n",
      "merge 72/244 : (93, 32) -> 327 (b'] ') had 458 occurences\n",
      "merge 73/244 : (324, 292) -> 328 (b'ginal ') had 453 occurences\n",
      "merge 74/244 : (317, 288) -> 329 (b'from the ') had 447 occurences\n",
      "merge 75/244 : (322, 328) -> 330 (b'original ') had 446 occurences\n",
      "merge 76/244 : (104, 256) -> 331 (b'he ') had 440 occurences\n",
      "merge 77/244 : (316, 326) -> 332 (b'Archi') had 440 occurences\n",
      "merge 78/244 : (332, 276) -> 333 (b'Archived ') had 440 occurences\n",
      "merge 79/244 : (329, 330) -> 334 (b'from the original ') had 440 occurences\n",
      "merge 80/244 : (333, 334) -> 335 (b'Archived from the original ') had 439 occurences\n",
      "merge 81/244 : (335, 279) -> 336 (b'Archived from the original on ') had 438 occurences\n",
      "merge 82/244 : (259, 336) -> 337 (b'. Archived from the original on ') had 433 occurences\n",
      "merge 83/244 : (97, 32) -> 338 (b'a ') had 420 occurences\n",
      "merge 84/244 : (115, 116) -> 339 (b'st') had 409 occurences\n",
      "merge 85/244 : (105, 99) -> 340 (b'ic') had 406 occurences\n",
      "merge 86/244 : (46, 91) -> 341 (b'.[') had 381 occurences\n",
      "merge 87/244 : (101, 99) -> 342 (b'ec') had 374 occurences\n",
      "merge 88/244 : (105, 301) -> 343 (b'ill') had 367 occurences\n",
      "merge 89/244 : (39, 262) -> 344 (b\"'s \") had 367 occurences\n",
      "merge 90/244 : (311, 266) -> 345 (b'Taylor Swift ') had 352 occurences\n",
      "merge 91/244 : (111, 118) -> 346 (b'ov') had 343 occurences\n",
      "merge 92/244 : (97, 116) -> 347 (b'at') had 334 occurences\n",
      "merge 93/244 : (97, 262) -> 348 (b'as ') had 315 occurences\n",
      "merge 94/244 : (101, 262) -> 349 (b'es ') had 309 occurences\n",
      "merge 95/244 : (74, 117) -> 350 (b'Ju') had 307 occurences\n",
      "merge 96/244 : (323, 32) -> 351 (b'of ') had 306 occurences\n",
      "merge 97/244 : (305, 32) -> 352 (b'to ') had 284 occurences\n",
      "merge 98/244 : (117, 109) -> 353 (b'um') had 281 occurences\n",
      "merge 99/244 : (84, 331) -> 354 (b'The ') had 277 occurences\n",
      "merge 100/244 : (271, 100) -> 355 (b'ard') had 277 occurences\n",
      "merge 101/244 : (263, 32) -> 356 (b'in ') had 276 occurences\n",
      "merge 102/244 : (270, 32) -> 357 (b'an ') had 276 occurences\n",
      "merge 103/244 : (101, 108) -> 358 (b'el') had 275 occurences\n",
      "merge 104/244 : (297, 51) -> 359 (b', 2023') had 271 occurences\n",
      "merge 105/244 : (271, 273) -> 360 (b'ary ') had 259 occurences\n",
      "merge 106/244 : (267, 32) -> 361 (b'th ') had 258 occurences\n",
      "merge 107/244 : (97, 109) -> 362 (b'am') had 257 occurences\n",
      "merge 108/244 : (108, 273) -> 363 (b'ly ') had 250 occurences\n",
      "merge 109/244 : (111, 112) -> 364 (b'op') had 249 occurences\n",
      "merge 110/244 : (311, 116) -> 365 (b'Taylor Swift') had 246 occurences\n",
      "merge 111/244 : (116, 114) -> 366 (b'tr') had 243 occurences\n",
      "merge 112/244 : (105, 115) -> 367 (b'is') had 234 occurences\n",
      "merge 113/244 : (104, 272) -> 368 (b'her ') had 232 occurences\n",
      "merge 114/244 : (111, 32) -> 369 (b'o ') had 225 occurences\n",
      "merge 115/244 : (117, 360) -> 370 (b'uary ') had 225 occurences\n",
      "merge 116/244 : (78, 346) -> 371 (b'Nov') had 222 occurences\n",
      "merge 117/244 : (312, 340) -> 372 (b'usic') had 221 occurences\n",
      "merge 118/244 : (371, 314) -> 373 (b'November ') had 221 occurences\n",
      "merge 119/244 : (101, 119) -> 374 (b'ew') had 219 occurences\n",
      "merge 120/244 : (97, 266) -> 375 (b'at ') had 219 occurences\n",
      "merge 121/244 : (108, 32) -> 376 (b'l ') had 218 occurences\n",
      "merge 122/244 : (58, 32) -> 377 (b': ') had 213 occurences\n",
      "merge 123/244 : (98, 111) -> 378 (b'bo') had 210 occurences\n",
      "merge 124/244 : (282, 266) -> 379 (b'Swift ') had 208 occurences\n",
      "merge 125/244 : (68, 342) -> 380 (b'Dec') had 207 occurences\n",
      "merge 126/244 : (105, 116) -> 381 (b'it') had 206 occurences\n",
      "merge 127/244 : (105, 103) -> 382 (b'ig') had 205 occurences\n",
      "merge 128/244 : (66, 343) -> 383 (b'Bill') had 205 occurences\n",
      "merge 129/244 : (49, 48) -> 384 (b'10') had 204 occurences\n",
      "merge 130/244 : (97, 115) -> 385 (b'as') had 203 occurences\n",
      "merge 131/244 : (264, 103) -> 386 (b'ong') had 202 occurences\n",
      "merge 132/244 : (79, 99) -> 387 (b'Oc') had 200 occurences\n",
      "merge 133/244 : (97, 298) -> 388 (b'ati') had 199 occurences\n",
      "merge 134/244 : (83, 116) -> 389 (b'St') had 198 occurences\n",
      "merge 135/244 : (387, 305) -> 390 (b'Octo') had 198 occurences\n",
      "merge 136/244 : (390, 287) -> 391 (b'October ') had 198 occurences\n",
      "merge 137/244 : (97, 99) -> 392 (b'ac') had 197 occurences\n",
      "merge 138/244 : (111, 119) -> 393 (b'ow') had 196 occurences\n",
      "merge 139/244 : (380, 314) -> 394 (b'December ') had 194 occurences\n",
      "merge 140/244 : (383, 378) -> 395 (b'Billbo') had 191 occurences\n",
      "merge 141/244 : (97, 100) -> 396 (b'ad') had 190 occurences\n",
      "merge 142/244 : (108, 101) -> 397 (b'le') had 190 occurences\n",
      "merge 143/244 : (117, 114) -> 398 (b'ur') had 188 occurences\n",
      "merge 144/244 : (102, 283) -> 399 (b'for ') had 188 occurences\n",
      "merge 145/244 : (32, 40) -> 400 (b' (') had 187 occurences\n",
      "merge 146/244 : (297, 50) -> 401 (b', 2022') had 187 occurences\n",
      "merge 147/244 : (117, 103) -> 402 (b'ug') had 185 occurences\n",
      "merge 148/244 : (284, 32) -> 403 (b'ch ') had 184 occurences\n",
      "merge 149/244 : (115, 266) -> 404 (b'st ') had 181 occurences\n",
      "merge 150/244 : (321, 110) -> 405 (b'oun') had 176 occurences\n",
      "merge 151/244 : (98, 353) -> 406 (b'bum') had 172 occurences\n",
      "merge 152/244 : (111, 108) -> 407 (b'ol') had 171 occurences\n",
      "merge 153/244 : (312, 266) -> 408 (b'ust ') had 171 occurences\n",
      "merge 154/244 : (101, 98) -> 409 (b'eb') had 170 occurences\n",
      "merge 155/244 : (77, 97) -> 410 (b'Ma') had 170 occurences\n",
      "merge 156/244 : (350, 363) -> 411 (b'July ') had 170 occurences\n",
      "merge 157/244 : (318, 345) -> 412 (b'). \"Taylor Swift ') had 169 occurences\n",
      "merge 158/244 : (107, 32) -> 413 (b'k ') had 165 occurences\n",
      "merge 159/244 : (278, 115) -> 414 (b'ers') had 164 occurences\n",
      "merge 160/244 : (93, 91) -> 415 (b'][') had 164 occurences\n",
      "merge 161/244 : (65, 402) -> 416 (b'Aug') had 164 occurences\n",
      "merge 162/244 : (416, 408) -> 417 (b'August ') had 163 occurences\n",
      "merge 163/244 : (105, 100) -> 418 (b'id') had 161 occurences\n",
      "merge 164/244 : (297, 49) -> 419 (b', 2021') had 160 occurences\n",
      "merge 165/244 : (109, 101) -> 420 (b'me') had 159 occurences\n",
      "merge 166/244 : (101, 112) -> 421 (b'ep') had 156 occurences\n",
      "merge 167/244 : (261, 49) -> 422 (b'201') had 149 occurences\n",
      "merge 168/244 : (50, 51) -> 423 (b'23') had 145 occurences\n",
      "merge 169/244 : (285, 50) -> 424 (b', 2012') had 144 occurences\n",
      "merge 170/244 : (101, 271) -> 425 (b'ear') had 140 occurences\n",
      "merge 171/244 : (269, 261) -> 426 (b', 2020') had 140 occurences\n",
      "merge 172/244 : (73, 110) -> 427 (b'In') had 139 occurences\n",
      "merge 173/244 : (102, 105) -> 428 (b'fi') had 139 occurences\n",
      "merge 174/244 : (110, 256) -> 429 (b'ne ') had 139 occurences\n",
      "merge 175/244 : (395, 355) -> 430 (b'Billboard') had 136 occurences\n",
      "merge 176/244 : (265, 116) -> 431 (b'rit') had 134 occurences\n",
      "merge 177/244 : (104, 105) -> 432 (b'hi') had 133 occurences\n",
      "merge 178/244 : (372, 32) -> 433 (b'usic ') had 133 occurences\n",
      "merge 179/244 : (304, 34) -> 434 (b'.\\n \"') had 133 occurences\n",
      "merge 180/244 : (78, 374) -> 435 (b'New') had 131 occurences\n",
      "merge 181/244 : (100, 105) -> 436 (b'di') had 130 occurences\n",
      "merge 182/244 : (65, 112) -> 437 (b'Ap') had 130 occurences\n",
      "merge 183/244 : (285, 57) -> 438 (b', 2019') had 129 occurences\n",
      "merge 184/244 : (114, 111) -> 439 (b'ro') had 128 occurences\n",
      "merge 185/244 : (39, 32) -> 440 (b\"' \") had 128 occurences\n",
      "merge 186/244 : (115, 257) -> 441 (b's, ') had 127 occurences\n",
      "merge 187/244 : (350, 429) -> 442 (b'June ') had 127 occurences\n",
      "merge 188/244 : (323, 288) -> 443 (b'of the ') had 126 occurences\n",
      "merge 189/244 : (99, 291) -> 444 (b'cor') had 126 occurences\n",
      "merge 190/244 : (50, 49) -> 445 (b'21') had 126 occurences\n",
      "merge 191/244 : (49, 57) -> 446 (b'19') had 124 occurences\n",
      "merge 192/244 : (105, 109) -> 447 (b'im') had 123 occurences\n",
      "merge 193/244 : (290, 32) -> 448 (b'en ') had 123 occurences\n",
      "merge 194/244 : (409, 114) -> 449 (b'ebr') had 122 occurences\n",
      "merge 195/244 : (290, 116) -> 450 (b'ent') had 121 occurences\n",
      "merge 196/244 : (111, 301) -> 451 (b'oll') had 121 occurences\n",
      "merge 197/244 : (77, 271) -> 452 (b'Mar') had 120 occurences\n",
      "merge 198/244 : (265, 99) -> 453 (b'ric') had 120 occurences\n",
      "merge 199/244 : (277, 361) -> 454 (b'with ') had 120 occurences\n",
      "merge 200/244 : (44, 91) -> 455 (b',[') had 118 occurences\n",
      "merge 201/244 : (70, 449) -> 456 (b'Febr') had 118 occurences\n",
      "merge 202/244 : (456, 370) -> 457 (b'February ') had 118 occurences\n",
      "merge 203/244 : (365, 344) -> 458 (b\"Taylor Swift's \") had 118 occurences\n",
      "merge 204/244 : (300, 430) -> 459 (b'\". Billboard') had 118 occurences\n",
      "merge 205/244 : (101, 97) -> 460 (b'ea') had 116 occurences\n",
      "merge 206/244 : (285, 54) -> 461 (b', 2016') had 116 occurences\n",
      "merge 207/244 : (421, 116) -> 462 (b'ept') had 115 occurences\n",
      "merge 208/244 : (410, 273) -> 463 (b'May ') had 115 occurences\n",
      "merge 209/244 : (285, 53) -> 464 (b', 2015') had 115 occurences\n",
      "merge 210/244 : (437, 265) -> 465 (b'Apri') had 115 occurences\n",
      "merge 211/244 : (465, 376) -> 466 (b'April ') had 115 occurences\n",
      "merge 212/244 : (108, 256) -> 467 (b'le ') had 113 occurences\n",
      "merge 213/244 : (65, 119) -> 468 (b'Aw') had 112 occurences\n",
      "merge 214/244 : (388, 264) -> 469 (b'ation') had 112 occurences\n",
      "merge 215/244 : (83, 462) -> 470 (b'Sept') had 112 occurences\n",
      "merge 216/244 : (470, 314) -> 471 (b'September ') had 112 occurences\n",
      "merge 217/244 : (114, 97) -> 472 (b'ra') had 111 occurences\n",
      "merge 218/244 : (274, 406) -> 473 (b'album') had 111 occurences\n",
      "merge 219/244 : (67, 104) -> 474 (b'Ch') had 110 occurences\n",
      "merge 220/244 : (118, 256) -> 475 (b've ') had 109 occurences\n",
      "merge 221/244 : (310, 266) -> 476 (b'est ') had 108 occurences\n",
      "merge 222/244 : (74, 270) -> 477 (b'Jan') had 108 occurences\n",
      "merge 223/244 : (50, 50) -> 478 (b'22') had 107 occurences\n",
      "merge 224/244 : (477, 370) -> 479 (b'January ') had 107 occurences\n",
      "merge 225/244 : (405, 366) -> 480 (b'ountr') had 106 occurences\n",
      "merge 226/244 : (382, 104) -> 481 (b'igh') had 106 occurences\n",
      "merge 227/244 : (300, 354) -> 482 (b'\". The ') had 106 occurences\n",
      "merge 228/244 : (359, 304) -> 483 (b', 2023.\\n ') had 106 occurences\n",
      "merge 229/244 : (49, 51) -> 484 (b'13') had 105 occurences\n",
      "merge 230/244 : (65, 108) -> 485 (b'Al') had 105 occurences\n",
      "merge 231/244 : (101, 116) -> 486 (b'et') had 105 occurences\n",
      "merge 232/244 : (310, 115) -> 487 (b'ess') had 103 occurences\n",
      "merge 233/244 : (452, 403) -> 488 (b'March ') had 103 occurences\n",
      "merge 234/244 : (117, 116) -> 489 (b'ut') had 102 occurences\n",
      "merge 235/244 : (119, 431) -> 490 (b'writ') had 101 occurences\n",
      "merge 236/244 : (108, 111) -> 491 (b'lo') had 99 occurences\n",
      "merge 237/244 : (208, 178) -> 492 (b'\\xd0\\xb2') had 98 occurences\n",
      "merge 238/244 : (115, 386) -> 493 (b'song') had 97 occurences\n",
      "merge 239/244 : (492, 208) -> 494 (b'\\xd0\\xb2\\xd0') had 97 occurences\n",
      "merge 240/244 : (494, 130) -> 495 (b'\\xd0\\xb2\\xd0\\x82') had 97 occurences\n",
      "merge 241/244 : (271, 258) -> 496 (b'ard ') had 97 occurences\n",
      "merge 242/244 : (48, 32) -> 497 (b'0 ') had 97 occurences\n",
      "merge 243/244 : (117, 108) -> 498 (b'ul') had 96 occurences\n",
      "merge 244/244 : (50, 52) -> 499 (b'24') had 95 occurences\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train(raw_text, vocab_size=500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345, 119, 279, 71, 114, 362, 109, 273, 109, 433, 97, 119, 355]\n"
     ]
    }
   ],
   "source": [
    "test = \"Taylor Swift won Grammy music award\"\n",
    "test_ids = tokenizer.encode(test)\n",
    "print(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taylor Swift won Grammy music award'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(test)) == \"Taylor Swift won Grammy music award\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 (BasicTokenizer -> RegexTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert you BasicTokenizer into a RegexTokenizer, which takes a regex pattern and splits the text exactly as GPT-4 would. Process the parts separately as before, then concatenate the results. Retrain your tokenizer and compare the results before and after. You should see that you will now have no tokens that go across categories (numbers, letters, punctuation, more than one whitespace). Use the GPT-4 pattern:\n",
    "\n",
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main GPT text split patterns, see\n",
    "# https://github.com/openai/tiktoken/blob/main/tiktoken_ext/openai_public.py\n",
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', \"'ve\", ' world', '123', ' how', \"'s\", ' are', ' you', '!!!?']\n",
      "['Hello', \"'ve\", ' world', '123', ' how', \"'s\", ' are', ' you', '!!!?']\n"
     ]
    }
   ],
   "source": [
    "gpt2pat = re.compile(GPT2_SPLIT_PATTERN)\n",
    "\n",
    "print(re.findall(gpt2pat, \"Hello've world123 how's are you!!!?\"))\n",
    "text_chunks = re.findall(gpt2pat, \"Hello've world123 how's are you!!!?\")\n",
    "print(text_chunks)  # we have here text chunks splitted by GPT2 split pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72, 101, 108, 108, 111], [39, 118, 101], [32, 119, 111, 114, 108, 100], [49, 50, 51], [32, 104, 111, 119], [39, 115], [32, 97, 114, 101], [32, 121, 111, 117], [33, 33, 33, 63]]\n"
     ]
    }
   ],
   "source": [
    "# creating ids for each text chunks seperately, ids will contain list of integers for each text chunks\n",
    "ids = [list(ch.encode(\"utf-8\")) for ch in text_chunks]\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(72, 101): 1, (101, 108): 1, (108, 108): 1, (108, 111): 1, (39, 118): 1, (118, 101): 1, (32, 119): 1, (119, 111): 1, (111, 114): 1, (114, 108): 1, (108, 100): 1, (49, 50): 1, (50, 51): 1, (32, 104): 1, (104, 111): 1, (111, 119): 1, (39, 115): 1, (32, 97): 1, (97, 114): 1, (114, 101): 1, (32, 121): 1, (121, 111): 1, (111, 117): 1, (33, 33): 2, (33, 63): 1}\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for chunk_ids in ids:\n",
    "    get_stats(chunk_ids, stats)\n",
    "    \n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's write RegexTokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "class RegexTokenizer:\n",
    "    def __init__(self, pattern = None):\n",
    "        super().__init__()\n",
    "        self.pattern = GPT4_SPLIT_PATTERN\n",
    "        self.compiled_pattern = re.compile(self.pattern)\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        assert vocab_size >= 256\n",
    "        num_merges = vocab_size - 256\n",
    "\n",
    "        # split text to text chunks\n",
    "        text_chunks = re.findall(self.compiled_pattern, text)\n",
    "\n",
    "        # taking ids\n",
    "        ids = [list(ch.encode(\"utf-8\")) for ch in text_chunks]\n",
    "\n",
    "        # iteratively merge the most common pairs to create new tokens\n",
    "        merges = {} # (int, int) -> int\n",
    "        vocab = {idx:bytes([idx]) for idx in range(256)}\n",
    "\n",
    "        stats = {}\n",
    "        for i in range(num_merges):\n",
    "            # count the frequency occurance of pairs\n",
    "            for chunk_ids in ids:\n",
    "                stats = get_stats(chunk_ids, stats)\n",
    "            # find the pair with the highest count\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = 256 + i\n",
    "            ids = [merge(chunk_ids, pair, idx) for chunk_ids in ids]\n",
    "            # save the merge\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
    "\n",
    "            # prints\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{num_merges}: {pair} -> {idx} ({vocab[idx]}) had {stats[pair]} occurrences\")\n",
    "        \n",
    "        # save the variables\n",
    "        self.merges = merges # using for encode()\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def _encode_chunk(self, text_bytes):\n",
    "        ''' return the token ids'''\n",
    "        \n",
    "        ids = list(text_bytes) \n",
    "        while len(ids) >= 2:\n",
    "            stats = get_stats(ids)\n",
    "            # find pair with lowest idx in merges\n",
    "            pair = min(stats, key=lambda p : self.merges.get(p, float(\"inf\")))\n",
    "            \n",
    "            if pair not in self.merges:\n",
    "                break # nothing else can be merged\n",
    "\n",
    "            # identify the index from merges\n",
    "            idx = self.merges[pair]\n",
    "            # merge the pair(lowest merge index)\n",
    "            ids = merge(ids, pair, idx)\n",
    "        return ids\n",
    "\n",
    "    def encode(self, text):\n",
    "        # split text into chunks of text by categories defined in regex pattern\n",
    "        text_chunks = re.findall(self.compiled_pattern, text)\n",
    "\n",
    "        # all chunks of text are encoded seperately, then results will be joined\n",
    "        ids = []\n",
    "        for chunk in text_chunks:\n",
    "            chunk_bytes = chunk.encode(\"utf-8\")  # raw bytes\n",
    "            chunk_ids = self._encode_chunk(chunk_bytes)\n",
    "            ids.extend(chunk_ids)\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        # given ids (list of integers), return Python string\n",
    "        text_bytes = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = RegexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of text:  185768\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(\"taylorswift.txt\", 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"the length of text: \", len(raw_text))\n",
    "#print(raw_text[850 : 2050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1/444: (101, 114) -> 256 (b'er') had 2359 occurrences\n",
      "merge 2/444: (50, 48) -> 257 (b'20') had 4374 occurrences\n",
      "merge 3/444: (111, 114) -> 258 (b'or') had 6228 occurrences\n",
      "merge 4/444: (105, 110) -> 259 (b'in') had 8024 occurrences\n",
      "merge 5/444: (101, 100) -> 260 (b'ed') had 9380 occurrences\n",
      "merge 6/444: (104, 101) -> 261 (b'he') had 11038 occurrences\n",
      "merge 7/444: (32, 116) -> 262 (b' t') had 12768 occurrences\n",
      "merge 8/444: (111, 110) -> 263 (b'on') had 14520 occurrences\n",
      "merge 9/444: (32, 83) -> 264 (b' S') had 14697 occurrences\n",
      "merge 10/444: (97, 114) -> 265 (b'ar') had 15190 occurrences\n",
      "merge 11/444: (97, 110) -> 266 (b'an') had 16357 occurrences\n",
      "merge 12/444: (32, 97) -> 267 (b' a') had 17183 occurrences\n",
      "merge 13/444: (114, 105) -> 268 (b'ri') had 17408 occurrences\n",
      "merge 14/444: (32, 65) -> 269 (b' A') had 18690 occurrences\n",
      "merge 15/444: (32, 65) -> 270 (b' A') had 18690 occurrences\n",
      "merge 16/444: (32, 65) -> 271 (b' A') had 18690 occurrences\n",
      "merge 17/444: (97, 108) -> 272 (b'al') had 19023 occurrences\n",
      "merge 18/444: (115, 116) -> 273 (b'st') had 19602 occurrences\n",
      "merge 19/444: (119, 105) -> 274 (b'wi') had 20079 occurrences\n",
      "merge 20/444: (32, 82) -> 275 (b' R') had 20900 occurrences\n",
      "merge 21/444: (32, 82) -> 276 (b' R') had 20900 occurrences\n",
      "merge 22/444: (32, 102) -> 277 (b' f') had 21274 occurrences\n",
      "merge 23/444: (32, 84) -> 278 (b' T') had 21482 occurrences\n",
      "merge 24/444: (102, 116) -> 279 (b'ft') had 22416 occurrences\n",
      "merge 25/444: (257, 49) -> 280 (b'201') had 22563 occurrences\n",
      "merge 26/444: (97, 121) -> 281 (b'ay') had 23400 occurrences\n",
      "merge 27/444: (118, 260) -> 282 (b'ved') had 24288 occurrences\n",
      "merge 28/444: (257, 50) -> 283 (b'202') had 24752 occurrences\n",
      "merge 29/444: (262, 261) -> 284 (b' the') had 25718 occurrences\n",
      "merge 30/444: (32, 34) -> 285 (b' \"') had 26460 occurrences\n",
      "merge 31/444: (32, 34) -> 286 (b' \"') had 26460 occurrences\n",
      "merge 32/444: (101, 116) -> 287 (b'et') had 27312 occurrences\n",
      "merge 33/444: (101, 115) -> 288 (b'es') had 27513 occurrences\n",
      "merge 34/444: (101, 115) -> 289 (b'es') had 27513 occurrences\n",
      "merge 35/444: (99, 104) -> 290 (b'ch') had 28009 occurrences\n",
      "merge 36/444: (111, 109) -> 291 (b'om') had 28404 occurrences\n",
      "merge 37/444: (98, 256) -> 292 (b'ber') had 28692 occurrences\n",
      "merge 38/444: (98, 256) -> 293 (b'ber') had 28692 occurrences\n",
      "merge 39/444: (98, 256) -> 294 (b'ber') had 28692 occurrences\n",
      "merge 40/444: (101, 110) -> 295 (b'en') had 29074 occurrences\n",
      "merge 41/444: (101, 110) -> 296 (b'en') had 29074 occurrences\n",
      "merge 42/444: (32, 111) -> 297 (b' o') had 29475 occurrences\n",
      "merge 43/444: (101, 109) -> 298 (b'em') had 30123 occurrences\n",
      "merge 44/444: (108, 108) -> 299 (b'll') had 30573 occurrences\n",
      "merge 45/444: (34, 46) -> 300 (b'\".') had 31215 occurrences\n",
      "merge 46/444: (97, 116) -> 301 (b'at') had 31818 occurrences\n",
      "merge 47/444: (32, 40) -> 302 (b' (') had 32195 occurrences\n",
      "merge 48/444: (46, 10) -> 303 (b'.\\n') had 32877 occurrences\n",
      "merge 49/444: (46, 10) -> 304 (b'.\\n') had 32877 occurrences\n",
      "merge 50/444: (32, 77) -> 305 (b' M') had 33100 occurrences\n",
      "merge 51/444: (105, 103) -> 306 (b'ig') had 33671 occurrences\n",
      "merge 52/444: (32, 115) -> 307 (b' s') had 33756 occurrences\n",
      "merge 53/444: (108, 258) -> 308 (b'lor') had 34000 occurrences\n",
      "merge 54/444: (105, 99) -> 309 (b'ic') had 34251 occurrences\n",
      "merge 55/444: (259, 103) -> 310 (b'ing') had 34884 occurrences\n",
      "merge 56/444: (114, 101) -> 311 (b're') had 35100 occurrences\n",
      "merge 57/444: (114, 101) -> 312 (b're') had 35100 occurrences\n",
      "merge 58/444: (114, 101) -> 313 (b're') had 35100 occurrences\n",
      "merge 59/444: (114, 101) -> 314 (b're') had 35100 occurrences\n",
      "merge 60/444: (114, 101) -> 315 (b're') had 35100 occurrences\n",
      "merge 61/444: (114, 101) -> 316 (b're') had 35100 occurrences\n",
      "merge 62/444: (32, 263) -> 317 (b' on') had 35316 occurrences\n",
      "merge 63/444: (264, 274) -> 318 (b' Swi') had 35948 occurrences\n",
      "merge 64/444: (264, 274) -> 319 (b' Swi') had 35948 occurrences\n",
      "merge 65/444: (264, 274) -> 320 (b' Swi') had 35948 occurrences\n",
      "merge 66/444: (111, 117) -> 321 (b'ou') had 36222 occurrences\n",
      "merge 67/444: (116, 105) -> 322 (b'ti') had 36342 occurrences\n",
      "merge 68/444: (101, 99) -> 323 (b'ec') had 36626 occurrences\n",
      "merge 69/444: (41, 46) -> 324 (b').') had 36921 occurrences\n",
      "merge 70/444: (32, 66) -> 325 (b' B') had 37100 occurrences\n",
      "merge 71/444: (268, 101) -> 326 (b'rie') had 37676 occurrences\n",
      "merge 72/444: (268, 101) -> 327 (b'rie') had 37676 occurrences\n",
      "merge 73/444: (268, 101) -> 328 (b'rie') had 37676 occurrences\n",
      "merge 74/444: (268, 101) -> 329 (b'rie') had 37676 occurrences\n",
      "merge 75/444: (268, 101) -> 330 (b'rie') had 37676 occurrences\n",
      "merge 76/444: (116, 104) -> 331 (b'th') had 37907 occurrences\n",
      "merge 77/444: (116, 104) -> 332 (b'th') had 37907 occurrences\n",
      "merge 78/444: (266, 100) -> 333 (b'and') had 38391 occurrences\n",
      "merge 79/444: (266, 100) -> 334 (b'and') had 38391 occurrences\n",
      "merge 80/444: (266, 100) -> 335 (b'and') had 38391 occurrences\n",
      "merge 81/444: (266, 100) -> 336 (b'and') had 38391 occurrences\n",
      "merge 82/444: (32, 67) -> 337 (b' C') had 38704 occurrences\n",
      "merge 83/444: (32, 78) -> 338 (b' N') had 39176 occurrences\n",
      "merge 84/444: (108, 101) -> 339 (b'le') had 39383 occurrences\n",
      "merge 85/444: (108, 101) -> 340 (b'le') had 39383 occurrences\n",
      "merge 86/444: (108, 101) -> 341 (b'le') had 39383 occurrences\n",
      "merge 87/444: (32, 74) -> 342 (b' J') had 39759 occurrences\n",
      "merge 88/444: (32, 74) -> 343 (b' J') had 39759 occurrences\n",
      "merge 89/444: (32, 258) -> 344 (b' or') had 39990 occurrences\n",
      "merge 90/444: (32, 258) -> 345 (b' or') had 39990 occurrences\n",
      "merge 91/444: (114, 111) -> 346 (b'ro') had 40072 occurrences\n",
      "merge 92/444: (114, 111) -> 347 (b'ro') had 40072 occurrences\n",
      "merge 93/444: (32, 104) -> 348 (b' h') had 40356 occurrences\n",
      "merge 94/444: (32, 104) -> 349 (b' h') had 40356 occurrences\n",
      "merge 95/444: (275, 287) -> 350 (b' Ret') had 40509 occurrences\n",
      "merge 96/444: (275, 287) -> 351 (b' Ret') had 40509 occurrences\n",
      "merge 97/444: (269, 114) -> 352 (b' Ar') had 40757 occurrences\n",
      "merge 98/444: (269, 114) -> 353 (b' Ar') had 40757 occurrences\n",
      "merge 99/444: (269, 114) -> 354 (b' Ar') had 40757 occurrences\n",
      "merge 100/444: (32, 119) -> 355 (b' w') had 40850 occurrences\n",
      "merge 101/444: (97, 115) -> 356 (b'as') had 41226 occurrences\n",
      "merge 102/444: (105, 116) -> 357 (b'it') had 41366 occurrences\n",
      "merge 103/444: (105, 116) -> 358 (b'it') had 41366 occurrences\n",
      "merge 104/444: (277, 114) -> 359 (b' fr') had 41600 occurrences\n",
      "merge 105/444: (277, 114) -> 360 (b' fr') had 41600 occurrences\n",
      "merge 106/444: (277, 114) -> 361 (b' fr') had 41600 occurrences\n",
      "merge 107/444: (32, 259) -> 362 (b' in') had 41612 occurrences\n",
      "merge 108/444: (32, 259) -> 363 (b' in') had 41612 occurrences\n",
      "merge 109/444: (259, 272) -> 364 (b'inal') had 41952 occurrences\n",
      "merge 110/444: (259, 272) -> 365 (b'inal') had 41952 occurrences\n",
      "merge 111/444: (32, 112) -> 366 (b' p') had 42291 occurrences\n",
      "merge 112/444: (32, 68) -> 367 (b' D') had 42560 occurrences\n",
      "merge 113/444: (32, 68) -> 368 (b' D') had 42560 occurrences\n",
      "merge 114/444: (117, 115) -> 369 (b'us') had 42828 occurrences\n",
      "merge 115/444: (117, 115) -> 370 (b'us') had 42828 occurrences\n",
      "merge 116/444: (318, 279) -> 371 (b' Swift') had 43301 occurrences\n",
      "merge 117/444: (318, 279) -> 372 (b' Swift') had 43301 occurrences\n",
      "merge 118/444: (39, 115) -> 373 (b\"'s\") had 43424 occurrences\n",
      "merge 119/444: (39, 115) -> 374 (b\"'s\") had 43424 occurrences\n",
      "merge 120/444: (281, 308) -> 375 (b'aylor') had 43550 occurrences\n",
      "merge 121/444: (281, 308) -> 376 (b'aylor') had 43550 occurrences\n",
      "merge 122/444: (32, 109) -> 377 (b' m') had 43798 occurrences\n",
      "merge 123/444: (32, 109) -> 378 (b' m') had 43798 occurrences\n",
      "merge 124/444: (32, 70) -> 379 (b' F') had 44144 occurrences\n",
      "merge 125/444: (105, 282) -> 380 (b'ived') had 44590 occurrences\n",
      "merge 126/444: (105, 282) -> 381 (b'ived') had 44590 occurrences\n",
      "merge 127/444: (32, 87) -> 382 (b' W') had 44831 occurrences\n",
      "merge 128/444: (32, 99) -> 383 (b' c') had 45095 occurrences\n",
      "merge 129/444: (298, 292) -> 384 (b'ember') had 45494 occurrences\n",
      "merge 130/444: (46, 91) -> 385 (b'.[') had 45557 occurrences\n",
      "merge 131/444: (46, 91) -> 386 (b'.[') had 45557 occurrences\n",
      "merge 132/444: (265, 100) -> 387 (b'ard') had 45628 occurrences\n",
      "merge 133/444: (105, 115) -> 388 (b'is') had 45858 occurrences\n",
      "merge 134/444: (105, 115) -> 389 (b'is') had 45858 occurrences\n",
      "merge 135/444: (105, 115) -> 390 (b'is') had 45858 occurrences\n",
      "merge 136/444: (99, 116) -> 391 (b'ct') had 46136 occurrences\n",
      "merge 137/444: (262, 111) -> 392 (b' to') had 46209 occurrences\n",
      "merge 138/444: (262, 111) -> 393 (b' to') had 46209 occurrences\n",
      "merge 139/444: (262, 111) -> 394 (b' to') had 46209 occurrences\n",
      "merge 140/444: (262, 111) -> 395 (b' to') had 46209 occurrences\n",
      "merge 141/444: (262, 111) -> 396 (b' to') had 46209 occurrences\n",
      "merge 142/444: (262, 111) -> 397 (b' to') had 46209 occurrences\n",
      "merge 143/444: (262, 111) -> 398 (b' to') had 46209 occurrences\n",
      "merge 144/444: (326, 282) -> 399 (b'rieved') had 46647 occurrences\n",
      "merge 145/444: (108, 121) -> 400 (b'ly') had 46725 occurrences\n",
      "merge 146/444: (108, 121) -> 401 (b'ly') had 46725 occurrences\n",
      "merge 147/444: (111, 118) -> 402 (b'ov') had 46988 occurrences\n",
      "merge 148/444: (111, 118) -> 403 (b'ov') had 46988 occurrences\n",
      "merge 149/444: (105, 263) -> 404 (b'ion') had 47243 occurrences\n",
      "merge 150/444: (297, 102) -> 405 (b' of') had 47412 occurrences\n",
      "merge 151/444: (297, 102) -> 406 (b' of') had 47412 occurrences\n",
      "merge 152/444: (297, 102) -> 407 (b' of') had 47412 occurrences\n",
      "merge 153/444: (32, 72) -> 408 (b' H') had 47430 occurrences\n",
      "merge 154/444: (32, 72) -> 409 (b' H') had 47430 occurrences\n",
      "merge 155/444: (32, 72) -> 410 (b' H') had 47430 occurrences\n",
      "merge 156/444: (32, 72) -> 411 (b' H') had 47430 occurrences\n",
      "merge 157/444: (32, 72) -> 412 (b' H') had 47430 occurrences\n",
      "merge 158/444: (32, 80) -> 413 (b' P') had 47716 occurrences\n",
      "merge 159/444: (32, 80) -> 414 (b' P') had 47716 occurrences\n",
      "merge 160/444: (32, 80) -> 415 (b' P') had 47716 occurrences\n",
      "merge 161/444: (32, 80) -> 416 (b' P') had 47716 occurrences\n",
      "merge 162/444: (32, 80) -> 417 (b' P') had 47716 occurrences\n",
      "merge 163/444: (32, 80) -> 418 (b' P') had 47716 occurrences\n",
      "merge 164/444: (32, 80) -> 419 (b' P') had 47716 occurrences\n",
      "merge 165/444: (118, 101) -> 420 (b've') had 47833 occurrences\n",
      "merge 166/444: (118, 101) -> 421 (b've') had 47833 occurrences\n",
      "merge 167/444: (118, 101) -> 422 (b've') had 47833 occurrences\n",
      "merge 168/444: (118, 101) -> 423 (b've') had 47833 occurrences\n",
      "merge 169/444: (118, 101) -> 424 (b've') had 47833 occurrences\n",
      "merge 170/444: (118, 101) -> 425 (b've') had 47833 occurrences\n",
      "merge 171/444: (117, 109) -> 426 (b'um') had 48051 occurrences\n",
      "merge 172/444: (117, 110) -> 427 (b'un') had 48252 occurrences\n",
      "merge 173/444: (32, 98) -> 428 (b' b') had 48440 occurrences\n",
      "merge 174/444: (32, 98) -> 429 (b' b') had 48440 occurrences\n",
      "merge 175/444: (105, 299) -> 430 (b'ill') had 48493 occurrences\n",
      "merge 176/444: (32, 71) -> 431 (b' G') had 48752 occurrences\n",
      "merge 177/444: (32, 71) -> 432 (b' G') had 48752 occurrences\n",
      "merge 178/444: (101, 108) -> 433 (b'el') had 48832 occurrences\n",
      "merge 179/444: (101, 108) -> 434 (b'el') had 48832 occurrences\n",
      "merge 180/444: (32, 333) -> 435 (b' and') had 48960 occurrences\n",
      "merge 181/444: (32, 333) -> 436 (b' and') had 48960 occurrences\n",
      "merge 182/444: (32, 333) -> 437 (b' and') had 48960 occurrences\n",
      "merge 183/444: (32, 333) -> 438 (b' and') had 48960 occurrences\n",
      "merge 184/444: (117, 108) -> 439 (b'ul') had 49022 occurrences\n",
      "merge 185/444: (114, 97) -> 440 (b'ra') had 49101 occurrences\n",
      "merge 186/444: (32, 73) -> 441 (b' I') had 49104 occurrences\n",
      "merge 187/444: (32, 73) -> 442 (b' I') had 49104 occurrences\n",
      "merge 188/444: (32, 73) -> 443 (b' I') had 49104 occurrences\n",
      "merge 189/444: (111, 112) -> 444 (b'op') had 49317 occurrences\n",
      "merge 190/444: (111, 112) -> 445 (b'op') had 49317 occurrences\n",
      "merge 191/444: (111, 112) -> 446 (b'op') had 49317 occurrences\n",
      "merge 192/444: (111, 112) -> 447 (b'op') had 49317 occurrences\n",
      "merge 193/444: (111, 112) -> 448 (b'op') had 49317 occurrences\n",
      "merge 194/444: (111, 112) -> 449 (b'op') had 49317 occurrences\n",
      "merge 195/444: (265, 121) -> 450 (b'ary') had 49395 occurrences\n",
      "merge 196/444: (265, 121) -> 451 (b'ary') had 49395 occurrences\n",
      "merge 197/444: (265, 121) -> 452 (b'ary') had 49395 occurrences\n",
      "merge 198/444: (265, 121) -> 453 (b'ary') had 49395 occurrences\n",
      "merge 199/444: (265, 121) -> 454 (b'ary') had 49395 occurrences\n",
      "merge 200/444: (344, 306) -> 455 (b' orig') had 49728 occurrences\n",
      "merge 201/444: (344, 306) -> 456 (b' orig') had 49728 occurrences\n",
      "merge 202/444: (32, 100) -> 457 (b' d') had 49894 occurrences\n",
      "merge 203/444: (32, 79) -> 458 (b' O') had 50141 occurrences\n",
      "merge 204/444: (359, 291) -> 459 (b' from') had 50300 occurrences\n",
      "merge 205/444: (359, 291) -> 460 (b' from') had 50300 occurrences\n",
      "merge 206/444: (359, 291) -> 461 (b' from') had 50300 occurrences\n",
      "merge 207/444: (359, 291) -> 462 (b' from') had 50300 occurrences\n",
      "merge 208/444: (97, 109) -> 463 (b'am') had 50484 occurrences\n",
      "merge 209/444: (97, 109) -> 464 (b'am') had 50484 occurrences\n",
      "merge 210/444: (97, 109) -> 465 (b'am') had 50484 occurrences\n",
      "merge 211/444: (97, 109) -> 466 (b'am') had 50484 occurrences\n",
      "merge 212/444: (352, 290) -> 467 (b' Arch') had 50600 occurrences\n",
      "merge 213/444: (352, 290) -> 468 (b' Arch') had 50600 occurrences\n",
      "merge 214/444: (352, 290) -> 469 (b' Arch') had 50600 occurrences\n",
      "merge 215/444: (117, 114) -> 470 (b'ur') had 50672 occurrences\n",
      "merge 216/444: (117, 114) -> 471 (b'ur') had 50672 occurrences\n",
      "merge 217/444: (117, 114) -> 472 (b'ur') had 50672 occurrences\n",
      "merge 218/444: (117, 114) -> 473 (b'ur') had 50672 occurrences\n",
      "merge 219/444: (117, 114) -> 474 (b'ur') had 50672 occurrences\n",
      "merge 220/444: (117, 114) -> 475 (b'ur') had 50672 occurrences\n",
      "merge 221/444: (117, 114) -> 476 (b'ur') had 50672 occurrences\n",
      "merge 222/444: (117, 114) -> 477 (b'ur') had 50672 occurrences\n",
      "merge 223/444: (32, 76) -> 478 (b' L') had 50844 occurrences\n",
      "merge 224/444: (350, 399) -> 479 (b' Retrieved') had 51120 occurrences\n",
      "merge 225/444: (350, 399) -> 480 (b' Retrieved') had 51120 occurrences\n",
      "merge 226/444: (350, 399) -> 481 (b' Retrieved') had 51120 occurrences\n",
      "merge 227/444: (350, 399) -> 482 (b' Retrieved') had 51120 occurrences\n",
      "merge 228/444: (350, 399) -> 483 (b' Retrieved') had 51120 occurrences\n",
      "merge 229/444: (350, 399) -> 484 (b' Retrieved') had 51120 occurrences\n",
      "merge 230/444: (350, 399) -> 485 (b' Retrieved') had 51120 occurrences\n",
      "merge 231/444: (350, 399) -> 486 (b' Retrieved') had 51120 occurrences\n",
      "merge 232/444: (97, 100) -> 487 (b'ad') had 51193 occurrences\n",
      "merge 233/444: (97, 100) -> 488 (b'ad') had 51193 occurrences\n",
      "merge 234/444: (110, 116) -> 489 (b'nt') had 51225 occurrences\n",
      "merge 235/444: (256, 115) -> 490 (b'ers') had 51403 occurrences\n",
      "merge 236/444: (101, 119) -> 491 (b'ew') had 51481 occurrences\n",
      "merge 237/444: (101, 119) -> 492 (b'ew') had 51481 occurrences\n",
      "merge 238/444: (117, 273) -> 493 (b'ust') had 51692 occurrences\n",
      "merge 239/444: (117, 273) -> 494 (b'ust') had 51692 occurrences\n",
      "merge 240/444: (104, 105) -> 495 (b'hi') had 51733 occurrences\n",
      "merge 241/444: (104, 105) -> 496 (b'hi') had 51733 occurrences\n",
      "merge 242/444: (104, 105) -> 497 (b'hi') had 51733 occurrences\n",
      "merge 243/444: (98, 111) -> 498 (b'bo') had 51759 occurrences\n",
      "merge 244/444: (98, 111) -> 499 (b'bo') had 51759 occurrences\n",
      "merge 245/444: (98, 111) -> 500 (b'bo') had 51759 occurrences\n",
      "merge 246/444: (98, 111) -> 501 (b'bo') had 51759 occurrences\n",
      "merge 247/444: (108, 98) -> 502 (b'lb') had 51795 occurrences\n",
      "merge 248/444: (108, 98) -> 503 (b'lb') had 51795 occurrences\n",
      "merge 249/444: (108, 98) -> 504 (b'lb') had 51795 occurrences\n",
      "merge 250/444: (108, 98) -> 505 (b'lb') had 51795 occurrences\n",
      "merge 251/444: (108, 98) -> 506 (b'lb') had 51795 occurrences\n",
      "merge 252/444: (108, 98) -> 507 (b'lb') had 51795 occurrences\n",
      "merge 253/444: (84, 375) -> 508 (b'Taylor') had 52136 occurrences\n",
      "merge 254/444: (105, 100) -> 509 (b'id') had 52200 occurrences\n",
      "merge 255/444: (101, 112) -> 510 (b'ep') had 52207 occurrences\n",
      "merge 256/444: (278, 261) -> 511 (b' The') had 52425 occurrences\n",
      "merge 257/444: (278, 261) -> 512 (b' The') had 52425 occurrences\n",
      "merge 258/444: (278, 261) -> 513 (b' The') had 52425 occurrences\n",
      "merge 259/444: (32, 69) -> 514 (b' E') had 52577 occurrences\n",
      "merge 260/444: (32, 69) -> 515 (b' E') had 52577 occurrences\n",
      "merge 261/444: (32, 69) -> 516 (b' E') had 52577 occurrences\n",
      "merge 262/444: (32, 69) -> 517 (b' E') had 52577 occurrences\n",
      "merge 263/444: (32, 69) -> 518 (b' E') had 52577 occurrences\n",
      "merge 264/444: (105, 108) -> 519 (b'il') had 52588 occurrences\n",
      "merge 265/444: (105, 108) -> 520 (b'il') had 52588 occurrences\n",
      "merge 266/444: (105, 108) -> 521 (b'il') had 52588 occurrences\n",
      "merge 267/444: (105, 108) -> 522 (b'il') had 52588 occurrences\n",
      "merge 268/444: (105, 108) -> 523 (b'il') had 52588 occurrences\n",
      "merge 269/444: (263, 103) -> 524 (b'ong') had 52722 occurrences\n",
      "merge 270/444: (263, 103) -> 525 (b'ong') had 52722 occurrences\n",
      "merge 271/444: (99, 101) -> 526 (b'ce') had 52770 occurrences\n",
      "merge 272/444: (99, 101) -> 527 (b'ce') had 52770 occurrences\n",
      "merge 273/444: (99, 101) -> 528 (b'ce') had 52770 occurrences\n",
      "merge 274/444: (99, 101) -> 529 (b'ce') had 52770 occurrences\n",
      "merge 275/444: (99, 101) -> 530 (b'ce') had 52770 occurrences\n",
      "merge 276/444: (99, 101) -> 531 (b'ce') had 52770 occurrences\n",
      "merge 277/444: (99, 101) -> 532 (b'ce') had 52770 occurrences\n",
      "merge 278/444: (99, 101) -> 533 (b'ce') had 52770 occurrences\n",
      "merge 279/444: (111, 108) -> 534 (b'ol') had 52871 occurrences\n",
      "merge 280/444: (105, 109) -> 535 (b'im') had 53056 occurrences\n",
      "merge 281/444: (117, 103) -> 536 (b'ug') had 53173 occurrences\n",
      "merge 282/444: (117, 103) -> 537 (b'ug') had 53173 occurrences\n",
      "merge 283/444: (117, 103) -> 538 (b'ug') had 53173 occurrences\n",
      "merge 284/444: (264, 116) -> 539 (b' St') had 53191 occurrences\n",
      "merge 285/444: (264, 116) -> 540 (b' St') had 53191 occurrences\n",
      "merge 286/444: (264, 116) -> 541 (b' St') had 53191 occurrences\n",
      "merge 287/444: (264, 116) -> 542 (b' St') had 53191 occurrences\n",
      "merge 288/444: (264, 116) -> 543 (b' St') had 53191 occurrences\n",
      "merge 289/444: (264, 116) -> 544 (b' St') had 53191 occurrences\n",
      "merge 290/444: (277, 258) -> 545 (b' for') had 53332 occurrences\n",
      "merge 291/444: (277, 258) -> 546 (b' for') had 53332 occurrences\n",
      "merge 292/444: (49, 48) -> 547 (b'10') had 53436 occurrences\n",
      "merge 293/444: (49, 48) -> 548 (b'10') had 53436 occurrences\n",
      "merge 294/444: (101, 265) -> 549 (b'ear') had 53486 occurrences\n",
      "merge 295/444: (101, 265) -> 550 (b'ear') had 53486 occurrences\n",
      "merge 296/444: (32, 266) -> 551 (b' an') had 53535 occurrences\n",
      "merge 297/444: (32, 266) -> 552 (b' an') had 53535 occurrences\n",
      "merge 298/444: (116, 256) -> 553 (b'ter') had 53591 occurrences\n",
      "merge 299/444: (116, 256) -> 554 (b'ter') had 53591 occurrences\n",
      "merge 300/444: (116, 256) -> 555 (b'ter') had 53591 occurrences\n",
      "merge 301/444: (116, 256) -> 556 (b'ter') had 53591 occurrences\n",
      "merge 302/444: (105, 101) -> 557 (b'ie') had 53648 occurrences\n",
      "merge 303/444: (111, 292) -> 558 (b'ober') had 53732 occurrences\n",
      "merge 304/444: (111, 292) -> 559 (b'ober') had 53732 occurrences\n",
      "merge 305/444: (111, 292) -> 560 (b'ober') had 53732 occurrences\n",
      "merge 306/444: (111, 119) -> 561 (b'ow') had 53896 occurrences\n",
      "merge 307/444: (111, 119) -> 562 (b'ow') had 53896 occurrences\n",
      "merge 308/444: (111, 119) -> 563 (b'ow') had 53896 occurrences\n",
      "merge 309/444: (111, 119) -> 564 (b'ow') had 53896 occurrences\n",
      "merge 310/444: (111, 119) -> 565 (b'ow') had 53896 occurrences\n",
      "merge 311/444: (111, 119) -> 566 (b'ow') had 53896 occurrences\n",
      "merge 312/444: (111, 119) -> 567 (b'ow') had 53896 occurrences\n",
      "merge 313/444: (111, 119) -> 568 (b'ow') had 53896 occurrences\n",
      "merge 314/444: (295, 116) -> 569 (b'ent') had 53939 occurrences\n",
      "merge 315/444: (295, 116) -> 570 (b'ent') had 53939 occurrences\n",
      "merge 316/444: (295, 116) -> 571 (b'ent') had 53939 occurrences\n",
      "merge 317/444: (295, 116) -> 572 (b'ent') had 53939 occurrences\n",
      "merge 318/444: (257, 48) -> 573 (b'200') had 54036 occurrences\n",
      "merge 319/444: (257, 48) -> 574 (b'200') had 54036 occurrences\n",
      "merge 320/444: (257, 48) -> 575 (b'200') had 54036 occurrences\n",
      "merge 321/444: (257, 48) -> 576 (b'200') had 54036 occurrences\n",
      "merge 322/444: (455, 364) -> 577 (b' original') had 54412 occurrences\n",
      "merge 323/444: (455, 364) -> 578 (b' original') had 54412 occurrences\n",
      "merge 324/444: (455, 364) -> 579 (b' original') had 54412 occurrences\n",
      "merge 325/444: (455, 364) -> 580 (b' original') had 54412 occurrences\n",
      "merge 326/444: (455, 364) -> 581 (b' original') had 54412 occurrences\n",
      "merge 327/444: (348, 256) -> 582 (b' her') had 54622 occurrences\n",
      "merge 328/444: (348, 256) -> 583 (b' her') had 54622 occurrences\n",
      "merge 329/444: (116, 115) -> 584 (b'ts') had 54730 occurrences\n",
      "merge 330/444: (116, 115) -> 585 (b'ts') had 54730 occurrences\n",
      "merge 331/444: (116, 115) -> 586 (b'ts') had 54730 occurrences\n",
      "merge 332/444: (116, 115) -> 587 (b'ts') had 54730 occurrences\n",
      "merge 333/444: (114, 121) -> 588 (b'ry') had 54753 occurrences\n",
      "merge 334/444: (93, 91) -> 589 (b'][') had 54776 occurrences\n",
      "merge 335/444: (278, 375) -> 590 (b' Taylor') had 54825 occurrences\n",
      "merge 336/444: (278, 375) -> 591 (b' Taylor') had 54825 occurrences\n",
      "merge 337/444: (467, 380) -> 592 (b' Archived') had 55000 occurrences\n",
      "merge 338/444: (467, 380) -> 593 (b' Archived') had 55000 occurrences\n",
      "merge 339/444: (467, 380) -> 594 (b' Archived') had 55000 occurrences\n",
      "merge 340/444: (101, 98) -> 595 (b'eb') had 55012 occurrences\n",
      "merge 341/444: (114, 117) -> 596 (b'ru') had 55081 occurrences\n",
      "merge 342/444: (114, 117) -> 597 (b'ru') had 55081 occurrences\n",
      "merge 343/444: (32, 86) -> 598 (b' V') had 55223 occurrences\n",
      "merge 344/444: (32, 311) -> 599 (b' re') had 55296 occurrences\n",
      "merge 345/444: (32, 311) -> 600 (b' re') had 55296 occurrences\n",
      "merge 346/444: (32, 39) -> 601 (b\" '\") had 55360 occurrences\n",
      "merge 347/444: (32, 39) -> 602 (b\" '\") had 55360 occurrences\n",
      "merge 348/444: (268, 116) -> 603 (b'rit') had 55478 occurrences\n",
      "merge 349/444: (268, 116) -> 604 (b'rit') had 55478 occurrences\n",
      "merge 350/444: (268, 116) -> 605 (b'rit') had 55478 occurrences\n",
      "merge 351/444: (268, 116) -> 606 (b'rit') had 55478 occurrences\n",
      "merge 352/444: (268, 116) -> 607 (b'rit') had 55478 occurrences\n",
      "merge 353/444: (268, 116) -> 608 (b'rit') had 55478 occurrences\n",
      "merge 354/444: (268, 116) -> 609 (b'rit') had 55478 occurrences\n",
      "merge 355/444: (268, 116) -> 610 (b'rit') had 55478 occurrences\n",
      "merge 356/444: (268, 116) -> 611 (b'rit') had 55478 occurrences\n",
      "merge 357/444: (268, 116) -> 612 (b'rit') had 55478 occurrences\n",
      "merge 358/444: (268, 116) -> 613 (b'rit') had 55478 occurrences\n",
      "merge 359/444: (268, 116) -> 614 (b'rit') had 55478 occurrences\n",
      "merge 360/444: (117, 116) -> 615 (b'ut') had 55535 occurrences\n",
      "merge 361/444: (117, 116) -> 616 (b'ut') had 55535 occurrences\n",
      "merge 362/444: (111, 116) -> 617 (b'ot') had 55539 occurrences\n",
      "merge 363/444: (111, 116) -> 618 (b'ot') had 55539 occurrences\n",
      "merge 364/444: (111, 116) -> 619 (b'ot') had 55539 occurrences\n",
      "merge 365/444: (111, 116) -> 620 (b'ot') had 55539 occurrences\n",
      "merge 366/444: (369, 309) -> 621 (b'usic') had 55692 occurrences\n",
      "merge 367/444: (32, 89) -> 622 (b' Y') had 55784 occurrences\n",
      "merge 368/444: (32, 89) -> 623 (b' Y') had 55784 occurrences\n",
      "merge 369/444: (32, 89) -> 624 (b' Y') had 55784 occurrences\n",
      "merge 370/444: (288, 115) -> 625 (b'ess') had 55942 occurrences\n",
      "merge 371/444: (105, 114) -> 626 (b'ir') had 56021 occurrences\n",
      "merge 372/444: (105, 114) -> 627 (b'ir') had 56021 occurrences\n",
      "merge 373/444: (105, 114) -> 628 (b'ir') had 56021 occurrences\n",
      "merge 374/444: (105, 114) -> 629 (b'ir') had 56021 occurrences\n",
      "merge 375/444: (105, 114) -> 630 (b'ir') had 56021 occurrences\n",
      "merge 376/444: (105, 114) -> 631 (b'ir') had 56021 occurrences\n",
      "merge 377/444: (105, 114) -> 632 (b'ir') had 56021 occurrences\n",
      "merge 378/444: (105, 114) -> 633 (b'ir') had 56021 occurrences\n",
      "merge 379/444: (105, 273) -> 634 (b'ist') had 56145 occurrences\n",
      "merge 380/444: (105, 273) -> 635 (b'ist') had 56145 occurrences\n",
      "merge 381/444: (105, 273) -> 636 (b'ist') had 56145 occurrences\n",
      "merge 382/444: (105, 273) -> 637 (b'ist') had 56145 occurrences\n",
      "merge 383/444: (105, 273) -> 638 (b'ist') had 56145 occurrences\n",
      "merge 384/444: (105, 273) -> 639 (b'ist') had 56145 occurrences\n",
      "merge 385/444: (105, 273) -> 640 (b'ist') had 56145 occurrences\n",
      "merge 386/444: (105, 273) -> 641 (b'ist') had 56145 occurrences\n",
      "merge 387/444: (105, 273) -> 642 (b'ist') had 56145 occurrences\n",
      "merge 388/444: (105, 273) -> 643 (b'ist') had 56145 occurrences\n",
      "merge 389/444: (105, 273) -> 644 (b'ist') had 56145 occurrences\n",
      "merge 390/444: (105, 273) -> 645 (b'ist') had 56145 occurrences\n",
      "merge 391/444: (105, 273) -> 646 (b'ist') had 56145 occurrences\n",
      "merge 392/444: (265, 116) -> 647 (b'art') had 56166 occurrences\n",
      "merge 393/444: (265, 116) -> 648 (b'art') had 56166 occurrences\n",
      "merge 394/444: (321, 114) -> 649 (b'our') had 56326 occurrences\n",
      "merge 395/444: (32, 274) -> 650 (b' wi') had 56400 occurrences\n",
      "merge 396/444: (32, 274) -> 651 (b' wi') had 56400 occurrences\n",
      "merge 397/444: (32, 274) -> 652 (b' wi') had 56400 occurrences\n",
      "merge 398/444: (32, 274) -> 653 (b' wi') had 56400 occurrences\n",
      "merge 399/444: (32, 274) -> 654 (b' wi') had 56400 occurrences\n",
      "merge 400/444: (32, 274) -> 655 (b' wi') had 56400 occurrences\n",
      "merge 401/444: (32, 274) -> 656 (b' wi') had 56400 occurrences\n",
      "merge 402/444: (32, 274) -> 657 (b' wi') had 56400 occurrences\n",
      "merge 403/444: (402, 384) -> 658 (b'ovember') had 56576 occurrences\n",
      "merge 404/444: (402, 384) -> 659 (b'ovember') had 56576 occurrences\n",
      "merge 405/444: (402, 384) -> 660 (b'ovember') had 56576 occurrences\n",
      "merge 406/444: (402, 384) -> 661 (b'ovember') had 56576 occurrences\n",
      "merge 407/444: (402, 384) -> 662 (b'ovember') had 56576 occurrences\n",
      "merge 408/444: (402, 384) -> 663 (b'ovember') had 56576 occurrences\n",
      "merge 409/444: (402, 384) -> 664 (b'ovember') had 56576 occurrences\n",
      "merge 410/444: (402, 384) -> 665 (b'ovember') had 56576 occurrences\n",
      "merge 411/444: (402, 384) -> 666 (b'ovember') had 56576 occurrences\n",
      "merge 412/444: (402, 384) -> 667 (b'ovember') had 56576 occurrences\n",
      "merge 413/444: (101, 273) -> 668 (b'est') had 56701 occurrences\n",
      "merge 414/444: (32, 110) -> 669 (b' n') had 56718 occurrences\n",
      "merge 415/444: (32, 110) -> 670 (b' n') had 56718 occurrences\n",
      "merge 416/444: (32, 110) -> 671 (b' n') had 56718 occurrences\n",
      "merge 417/444: (32, 110) -> 672 (b' n') had 56718 occurrences\n",
      "merge 418/444: (32, 110) -> 673 (b' n') had 56718 occurrences\n",
      "merge 419/444: (32, 110) -> 674 (b' n') had 56718 occurrences\n",
      "merge 420/444: (323, 384) -> 675 (b'ecember') had 56745 occurrences\n",
      "merge 421/444: (323, 384) -> 676 (b'ecember') had 56745 occurrences\n",
      "merge 422/444: (323, 384) -> 677 (b'ecember') had 56745 occurrences\n",
      "merge 423/444: (323, 384) -> 678 (b'ecember') had 56745 occurrences\n",
      "merge 424/444: (323, 384) -> 679 (b'ecember') had 56745 occurrences\n",
      "merge 425/444: (323, 384) -> 680 (b'ecember') had 56745 occurrences\n",
      "merge 426/444: (115, 101) -> 681 (b'se') had 56772 occurrences\n",
      "merge 427/444: (115, 101) -> 682 (b'se') had 56772 occurrences\n",
      "merge 428/444: (115, 101) -> 683 (b'se') had 56772 occurrences\n",
      "merge 429/444: (115, 101) -> 684 (b'se') had 56772 occurrences\n",
      "merge 430/444: (118, 256) -> 685 (b'ver') had 56871 occurrences\n",
      "merge 431/444: (118, 256) -> 686 (b'ver') had 56871 occurrences\n",
      "merge 432/444: (118, 256) -> 687 (b'ver') had 56871 occurrences\n",
      "merge 433/444: (118, 256) -> 688 (b'ver') had 56871 occurrences\n",
      "merge 434/444: (32, 108) -> 689 (b' l') had 56993 occurrences\n",
      "merge 435/444: (32, 108) -> 690 (b' l') had 56993 occurrences\n",
      "merge 436/444: (32, 108) -> 691 (b' l') had 56993 occurrences\n",
      "merge 437/444: (32, 108) -> 692 (b' l') had 56993 occurrences\n",
      "merge 438/444: (32, 108) -> 693 (b' l') had 56993 occurrences\n",
      "merge 439/444: (32, 108) -> 694 (b' l') had 56993 occurrences\n",
      "merge 440/444: (32, 108) -> 695 (b' l') had 56993 occurrences\n",
      "merge 441/444: (267, 116) -> 696 (b' at') had 57057 occurrences\n",
      "merge 442/444: (267, 116) -> 697 (b' at') had 57057 occurrences\n",
      "merge 443/444: (267, 116) -> 698 (b' at') had 57057 occurrences\n",
      "merge 444/444: (267, 116) -> 699 (b' at') had 57057 occurrences\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer.train(raw_text, vocab_size=700, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 376, 320, 279, 32, 390, 267, 277, 466, 321, 115, 32, 273, 265, 363, 284, 355, 258, 108, 100]\n"
     ]
    }
   ],
   "source": [
    "txt = \"Taylor Swift is a famous star in the world\"\n",
    "print(regex_tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 376, 320, 279, 32, 390, 267, 277, 466, 321, 115, 32, 273, 265, 363, 284, 355, 258, 108, 100]\n"
     ]
    }
   ],
   "source": [
    "txt = \"Taylor Swift is a famous star in the world\"\n",
    "ids = regex_tokenizer.encode(txt)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taylor Swift is a famous star in the world'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt == regex_tokenizer.decode(regex_tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare BasicTokenizer with RegexTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 376, 320, 279, 32, 390, 267, 277, 466, 321, 115, 32, 273, 265, 363, 284, 355, 258, 108, 100]\n",
      "[345, 105, 262, 338, 102, 362, 321, 262, 339, 97, 260, 263, 288, 119, 291, 108, 100]\n"
     ]
    }
   ],
   "source": [
    "txt = \"Taylor Swift is a famous star in the world\"\n",
    "ids_reg = regex_tokenizer.encode(txt)\n",
    "ids_basic = tokenizer.encode(txt)\n",
    "\n",
    "print(ids_reg)\n",
    "print(ids_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt == regex_tokenizer.decode(regex_tokenizer.encode(txt))\n",
    "txt == tokenizer.decode(tokenizer.encode(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're now ready to load the merges from the GPT-4 tokenizer and show that your tokenizer produces the identical results for both encode and decode, matching tiktoken.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!!!? (안녕하세요!) lol123 😉\n"
     ]
    }
   ],
   "source": [
    "# match this\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\") # this is the GPT-4 tokenizer\n",
    "ids = enc.encode(\"hello world!!!? (안녕하세요!) lol123 😉\")\n",
    "text = enc.decode(ids) # get the same text back\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == \"hello world!!!? (안녕하세요!) lol123 😉\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_reg = RegexTokenizer()\n",
    "# ids_my = tokenizer_reg.encode(\"hello world!!!? (안녕하세요!) lol123 😉\")  # not encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unfortunately, you will run into two issues:**\n",
    "\n",
    "- It is not trivial to recover the raw merges from the GPT-4 tokenizer. You can easily recover what we call vocab here, and what they call and store under enc._mergeable_ranks. Feel free to copy paste the recover_merges function in minbpe/gpt4.py, which takes these ranks and returns the raw merges. If you wish to know how this function works, read this and this. Basically, under some conditions it is enough to only store the parent nodes (and their rank) and get rid of the precise details of which children merged up to any parent.\n",
    "\n",
    "- Second, the GPT-4 tokenizer for some reason permutes its raw bytes. It stores this permutation in the first 256 elements of the mergeable ranks, so you can recover this byte shuffle relatively simply as byte_shuffle = {i: enc._mergeable_ranks[bytes([i])] for i in range(256)}. In both your encode and decode, you'll have to shuffle bytes around accordingly. If you're stuck, reference the minbpe/gpt4.py` file for hints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
